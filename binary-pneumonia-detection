{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kmljts/binary-pneumonia-detection?scriptVersionId=179371184\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# import os\n# for root, folders, filenames in os.walk('/kaggle/input'):\n#    print(root, folders)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:21:52.61537Z","iopub.execute_input":"2024-05-23T15:21:52.615917Z","iopub.status.idle":"2024-05-23T15:21:52.620122Z","shell.execute_reply.started":"2024-05-23T15:21:52.61589Z","shell.execute_reply":"2024-05-23T15:21:52.619214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:21:52.621514Z","iopub.execute_input":"2024-05-23T15:21:52.621778Z","iopub.status.idle":"2024-05-23T15:21:53.625299Z","shell.execute_reply.started":"2024-05-23T15:21:52.621756Z","shell.execute_reply":"2024-05-23T15:21:53.624271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom torchvision import datasets, transforms, models\nfrom torchmetrics import ConfusionMatrix, AUROC\nfrom mlxtend.plotting import plot_confusion_matrix\n\nimport os\nfrom datetime import datetime, timedelta\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nimport pandas as pd\nimport random\n\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:21:53.627484Z","iopub.execute_input":"2024-05-23T15:21:53.627801Z","iopub.status.idle":"2024-05-23T15:22:02.816308Z","shell.execute_reply.started":"2024-05-23T15:21:53.627767Z","shell.execute_reply":"2024-05-23T15:22:02.815504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dir = '/kaggle/input'\ndataset_path = os.path.join(input_dir, 'chest-xray-pneumonia/chest_xray/chest_xray')\ntrain_dataset_path = os.path.join(dataset_path, 'train')\nval_dataset_path = os.path.join(dataset_path, 'val')\ntest_dataset_path = os.path.join(dataset_path, 'test')\n\noutput_dir = '/kaggle/working'\nmodel_save_path = os.path.join(output_dir, 'models')\nresult_save_path = os.path.join(output_dir, 'results')\nplot_save_path = os.path.join(output_dir, 'plots')\n\nos.makedirs(model_save_path, exist_ok=True)\nos.makedirs(result_save_path, exist_ok=True)\nos.makedirs(plot_save_path, exist_ok=True)\n\ntrain_dataset_path, val_dataset_path, test_dataset_path, model_save_path, result_save_path, plot_save_path","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:02.817383Z","iopub.execute_input":"2024-05-23T15:22:02.818014Z","iopub.status.idle":"2024-05-23T15:22:02.830117Z","shell.execute_reply.started":"2024-05-23T15:22:02.817978Z","shell.execute_reply":"2024-05-23T15:22:02.829208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:02.83277Z","iopub.execute_input":"2024-05-23T15:22:02.833214Z","iopub.status.idle":"2024-05-23T15:22:02.840113Z","shell.execute_reply.started":"2024-05-23T15:22:02.83318Z","shell.execute_reply":"2024-05-23T15:22:02.839273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sorted(os.listdir(model_save_path)), sorted(os.listdir(result_save_path)), sorted(os.listdir(plot_save_path))","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:02.841224Z","iopub.execute_input":"2024-05-23T15:22:02.841779Z","iopub.status.idle":"2024-05-23T15:22:02.850835Z","shell.execute_reply.started":"2024-05-23T15:22:02.841753Z","shell.execute_reply":"2024-05-23T15:22:02.850075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:02.852231Z","iopub.execute_input":"2024-05-23T15:22:02.852488Z","iopub.status.idle":"2024-05-23T15:22:02.888844Z","shell.execute_reply.started":"2024-05-23T15:22:02.852466Z","shell.execute_reply":"2024-05-23T15:22:02.887916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:02.889773Z","iopub.execute_input":"2024-05-23T15:22:02.890027Z","iopub.status.idle":"2024-05-23T15:22:02.898028Z","shell.execute_reply.started":"2024-05-23T15:22:02.890006Z","shell.execute_reply":"2024-05-23T15:22:02.897236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 8\nLR = 1e-6\nEPOCHS = 50\n\nUSE_BEST_MODEL_YET = False\nNORMALIZE = True","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:02.898974Z","iopub.execute_input":"2024-05-23T15:22:02.899224Z","iopub.status.idle":"2024-05-23T15:22:02.90699Z","shell.execute_reply.started":"2024-05-23T15:22:02.899203Z","shell.execute_reply":"2024-05-23T15:22:02.90613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:02.908497Z","iopub.execute_input":"2024-05-23T15:22:02.909251Z","iopub.status.idle":"2024-05-23T15:22:02.917138Z","shell.execute_reply.started":"2024-05-23T15:22:02.90922Z","shell.execute_reply":"2024-05-23T15:22:02.916277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def current_datetime():\n    cur_datetime = datetime.now() + timedelta(hours=5, minutes=30) # IST\n    return cur_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n\ndef unique_file_namer(model_name, n_epochs=EPOCHS, learning_rate=LR, batch_size=BATCH_SIZE):\n    return f'{current_datetime()}_{model_name}_{n_epochs}_{learning_rate:.2e}_{batch_size}'","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:02.920369Z","iopub.execute_input":"2024-05-23T15:22:02.920628Z","iopub.status.idle":"2024-05-23T15:22:02.928975Z","shell.execute_reply.started":"2024-05-23T15:22:02.920606Z","shell.execute_reply":"2024-05-23T15:22:02.928018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UnNormalize:\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, tensor):\n        return tensor.clamp(-1, 1) * self.std + self.mean\n    \nclass Identity:\n    def __call__(self, tensor):\n        return tensor\n\nimg_to_tensor = transforms.Compose([\n    transforms.Resize((448,) * 2),\n#     transforms.RandomRotation(30),\n#     transforms.RandomResizedCrop((128,) * 2),\n#     transforms.RandomHorizontalFlip(),\n#     transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n#     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=0.0),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5]) if NORMALIZE else Identity()\n])\n\ntensor_to_img = transforms.Compose([\n    UnNormalize(0.5, 0.5) if NORMALIZE else Identity(),\n    transforms.ToPILImage()\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:02.930215Z","iopub.execute_input":"2024-05-23T15:22:02.93056Z","iopub.status.idle":"2024-05-23T15:22:02.94364Z","shell.execute_reply.started":"2024-05-23T15:22:02.93053Z","shell.execute_reply":"2024-05-23T15:22:02.942792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_sample(dataset, classes):\n    input, target = random.choice(dataset)\n\n    image = tensor_to_img(input)\n    display(image)\n    print('Target:', classes[target])\n\ndef random_pred(dataset, model, classes):\n    input, target = random.choice(dataset)\n\n    input = input.to(device)\n    image = tensor_to_img(input)\n    display(image)\n\n    model.eval()\n    with torch.inference_mode():\n        logits = model(input.unsqueeze(0))\n\n    print(f'{\"Raw Logits: \":30}{logits}') # raw logits\n    probs = logits.softmax(1)\n    print(f'{\"Prediction Probabilities: \":30}{probs}') # prediction probabilities\n    label = probs.argmax(1).item()\n    print(f'{\"Prediction Labels: \":30}{label}', end='\\n\\n') # prediction label\n    \n    print('Prediction:', classes[label])\n    print('Target:', classes[target])\n\ndef dataset_analyzer(dataset, classes):\n    freqs = [0] * len(classes)\n    for X, y in dataset:\n        freqs[y] += 1\n\n    return {classes[i]: freqs[i] for i in range(len(classes))}","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:02.944721Z","iopub.execute_input":"2024-05-23T15:22:02.945027Z","iopub.status.idle":"2024-05-23T15:22:02.954151Z","shell.execute_reply.started":"2024-05-23T15:22:02.944999Z","shell.execute_reply":"2024-05-23T15:22:02.953288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def harmonic_mean(a, b):\n    if a + b == 0: return 0\n    return 2 * a * b / (a + b)\n\ndef manage_nan(tensor):\n    return tensor if not torch.isnan(tensor).item() else torch.tensor(0.0).to(device)\n\ndef confmat_to_accuracy(confmat): # micro\n    num_classes = confmat.shape[0]\n\n    correct_preds = 0\n    for i in range(num_classes):\n        correct_preds += confmat[i, i]\n    all_preds = confmat.sum()\n\n    acc = manage_nan(correct_preds / all_preds)\n\n    return acc.item()\n\ndef confmat_to_precision(confmat): # macro\n    num_classes = confmat.shape[0]\n\n    if num_classes == 2:\n        return manage_nan(confmat[1, 1] / confmat[:, 1].sum()).item()\n\n    prec = 0\n    for i in range(num_classes):\n        prec += manage_nan(confmat[i, i] / confmat[:, i].sum())\n    prec /= num_classes\n\n    return prec.item()\n\ndef confmat_to_recall(confmat): # macro\n    num_classes = confmat.shape[0]\n\n    if num_classes == 2:\n        return manage_nan(confmat[1, 1] / confmat[1].sum()).item()\n\n    rec = 0\n    for i in range(num_classes):\n        rec += manage_nan(confmat[i, i] / confmat[i].sum())\n    rec /= num_classes\n\n    return rec.item()\n\ndef confmat_to_f1score(confmat): # macro\n    num_classes = confmat.shape[0]\n\n    if num_classes == 2:\n        return harmonic_mean(confmat_to_precision(confmat), confmat_to_recall(confmat))\n\n    f1 = 0\n    for i in range(num_classes):\n        prec = manage_nan(confmat[i, i] / confmat[:, i].sum())\n        rec = manage_nan(confmat[i, i] / confmat[i].sum())\n\n        f1 += harmonic_mean(prec, rec)\n    f1 /= num_classes\n\n    return f1.item()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:02.955322Z","iopub.execute_input":"2024-05-23T15:22:02.955579Z","iopub.status.idle":"2024-05-23T15:22:02.968896Z","shell.execute_reply.started":"2024-05-23T15:22:02.955557Z","shell.execute_reply":"2024-05-23T15:22:02.968128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = datasets.ImageFolder(train_dataset_path, transform=img_to_tensor)\n\nlen(train_dataset), random.choice(train_dataset), train_dataset.classes","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:02.969961Z","iopub.execute_input":"2024-05-23T15:22:02.970236Z","iopub.status.idle":"2024-05-23T15:22:05.816818Z","shell.execute_reply.started":"2024-05-23T15:22:02.970213Z","shell.execute_reply":"2024-05-23T15:22:05.815862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dataset = datasets.ImageFolder(val_dataset_path, transform=img_to_tensor)\n\nlen(val_dataset), random.choice(val_dataset), val_dataset.classes","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:05.818648Z","iopub.execute_input":"2024-05-23T15:22:05.819111Z","iopub.status.idle":"2024-05-23T15:22:05.852356Z","shell.execute_reply.started":"2024-05-23T15:22:05.819077Z","shell.execute_reply":"2024-05-23T15:22:05.851299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = datasets.ImageFolder(test_dataset_path, transform=img_to_tensor)\n\nlen(test_dataset), random.choice(test_dataset), test_dataset.classes","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:05.853663Z","iopub.execute_input":"2024-05-23T15:22:05.85409Z","iopub.status.idle":"2024-05-23T15:22:05.984394Z","shell.execute_reply.started":"2024-05-23T15:22:05.854056Z","shell.execute_reply":"2024-05-23T15:22:05.983499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_sample(train_dataset, classes=train_dataset.classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:05.985452Z","iopub.execute_input":"2024-05-23T15:22:05.985727Z","iopub.status.idle":"2024-05-23T15:22:06.079261Z","shell.execute_reply.started":"2024-05-23T15:22:05.985697Z","shell.execute_reply":"2024-05-23T15:22:06.078427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:06.080467Z","iopub.execute_input":"2024-05-23T15:22:06.081231Z","iopub.status.idle":"2024-05-23T15:22:06.086999Z","shell.execute_reply.started":"2024-05-23T15:22:06.081196Z","shell.execute_reply":"2024-05-23T15:22:06.086104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_dataloader), len(val_dataloader), len(test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:06.08826Z","iopub.execute_input":"2024-05-23T15:22:06.088563Z","iopub.status.idle":"2024-05-23T15:22:06.099921Z","shell.execute_reply.started":"2024-05-23T15:22:06.088537Z","shell.execute_reply":"2024-05-23T15:22:06.099014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# n_samples = torch.zeros(2)\n\n# for X, y in train_dataset:\n#     n_samples[y] += 1\n\nn_samples = torch.tensor([1341, 3875]).to(device)\n\nn_samples","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:06.100936Z","iopub.execute_input":"2024-05-23T15:22:06.101217Z","iopub.status.idle":"2024-05-23T15:22:06.24757Z","shell.execute_reply.started":"2024-05-23T15:22:06.101194Z","shell.execute_reply":"2024-05-23T15:22:06.246677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weights = n_samples.sum() / n_samples\n\nclass_weights","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:06.248944Z","iopub.execute_input":"2024-05-23T15:22:06.249315Z","iopub.status.idle":"2024-05-23T15:22:06.505757Z","shell.execute_reply.started":"2024-05-23T15:22:06.249282Z","shell.execute_reply":"2024-05-23T15:22:06.504907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PneumoniaDetector(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.resnet = models.resnet18(weights='DEFAULT')\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 2) # in_features = 512\n\n    def forward(self, x):\n        return self.resnet(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:06.50678Z","iopub.execute_input":"2024-05-23T15:22:06.507034Z","iopub.status.idle":"2024-05-23T15:22:06.512507Z","shell.execute_reply.started":"2024-05-23T15:22:06.507012Z","shell.execute_reply":"2024-05-23T15:22:06.511685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = PneumoniaDetector().to(device)\n\nif USE_BEST_MODEL_YET:\n    best_model_name = sorted(os.listdir(model_save_path))[-1]\n    best_model_path = os.path.join(model_save_path, best_model_name)\n    print(best_model_path)\n    model.load_state_dict(torch.load(best_model_path))","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:06.513631Z","iopub.execute_input":"2024-05-23T15:22:06.513961Z","iopub.status.idle":"2024-05-23T15:22:07.26721Z","shell.execute_reply.started":"2024-05-23T15:22:06.513932Z","shell.execute_reply":"2024-05-23T15:22:07.266454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nwith torch.inference_mode():\n    pred = model(random.choice(train_dataset)[0].to(device).unsqueeze(0))\npred","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:07.268409Z","iopub.execute_input":"2024-05-23T15:22:07.268746Z","iopub.status.idle":"2024-05-23T15:22:07.834917Z","shell.execute_reply.started":"2024-05-23T15:22:07.268721Z","shell.execute_reply":"2024-05-23T15:22:07.834044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_pred(train_dataset, model, classes=train_dataset.classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:07.836248Z","iopub.execute_input":"2024-05-23T15:22:07.836607Z","iopub.status.idle":"2024-05-23T15:22:08.012876Z","shell.execute_reply.started":"2024-05-23T15:22:07.836576Z","shell.execute_reply":"2024-05-23T15:22:08.012007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(weight=class_weights)\nconfmat_metric = ConfusionMatrix(task='multiclass', num_classes=2).to(device)\nauroc_metric = AUROC(task='multiclass', num_classes=2).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=LR)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:08.01401Z","iopub.execute_input":"2024-05-23T15:22:08.014306Z","iopub.status.idle":"2024-05-23T15:22:08.021395Z","shell.execute_reply.started":"2024-05-23T15:22:08.01428Z","shell.execute_reply":"2024-05-23T15:22:08.020628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses = []\nval_losses = []\naccs = []\nprecs = []\nrecs = []\nf1s = []\naurocs = []","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:08.022453Z","iopub.execute_input":"2024-05-23T15:22:08.022749Z","iopub.status.idle":"2024-05-23T15:22:08.029571Z","shell.execute_reply.started":"2024-05-23T15:22:08.022726Z","shell.execute_reply":"2024-05-23T15:22:08.028839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses, val_losses, accs, precs, recs, f1s, aurocs","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:08.034226Z","iopub.execute_input":"2024-05-23T15:22:08.034576Z","iopub.status.idle":"2024-05-23T15:22:08.040876Z","shell.execute_reply.started":"2024-05-23T15:22:08.034544Z","shell.execute_reply":"2024-05-23T15:22:08.040125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = 0\nauroc = 0\nmaster_confmat = torch.zeros(2, 2).to(device)\n\nmodel.eval()\nwith torch.inference_mode():\n    for X, y in tqdm(test_dataloader):\n        X, y = X.to(device), y.to(device)\n        logits = model(X)\n        probs = logits.softmax(1)\n        labels = probs.argmax(1)\n\n        loss += criterion(logits, y).item()\n        auroc += auroc_metric(probs, y).item()\n        master_confmat += confmat_metric(labels, y)\n\nloss /= len(test_dataloader)\nauroc /= len(test_dataloader)\nacc = confmat_to_accuracy(master_confmat)\nprec = confmat_to_precision(master_confmat)\nrec = confmat_to_recall(master_confmat)\nf1 = confmat_to_f1score(master_confmat)\n\ntrain_losses.append(loss)\nval_losses.append(loss)\naccs.append(acc)\nprecs.append(prec)\nrecs.append(rec)\nf1s.append(f1)\naurocs.append(auroc)\n\nprint(f'Cross Entropy Loss: {loss:.4f}')\nprint(f'Accuracy: {acc * 100:.2f}% | Precision: {prec * 100:.2f}% | Recall: {rec * 100:.2f}% | F1 Score: {f1 * 100:.2f}%')\nprint(f'AUROC: {auroc:.4f}')\n\nfig, ax = plot_confusion_matrix(\n    conf_mat=master_confmat.cpu().numpy(),\n    class_names=train_dataset.classes,\n    colorbar=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:08.04186Z","iopub.execute_input":"2024-05-23T15:22:08.042172Z","iopub.status.idle":"2024-05-23T15:22:25.7395Z","shell.execute_reply.started":"2024-05-23T15:22:08.042149Z","shell.execute_reply":"2024-05-23T15:22:25.738622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_acc = acc\nbest_acc_epoch = 0","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:25.740768Z","iopub.execute_input":"2024-05-23T15:22:25.741147Z","iopub.status.idle":"2024-05-23T15:22:25.74547Z","shell.execute_reply.started":"2024-05-23T15:22:25.741112Z","shell.execute_reply":"2024-05-23T15:22:25.744482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prev_size = len(train_losses)\n\nfor epoch in tqdm(range(EPOCHS)):\n    train_loss = 0\n    val_loss = 0\n    auroc = 0\n    master_confmat = torch.zeros(2, 2).to(device)\n\n    model.train()\n    for X, y in tqdm(train_dataloader):\n        X, y = X.to(device), y.to(device)\n        pred = model(X)\n        loss = criterion(pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    model.eval()\n    with torch.inference_mode():\n        for X, y in tqdm(test_dataloader):\n            X, y = X.to(device), y.to(device)\n            logits = model(X)\n            probs = logits.softmax(1)\n            labels = probs.argmax(1)\n\n            val_loss += criterion(logits, y).item()\n            auroc += auroc_metric(probs, y).item()\n            master_confmat += confmat_metric(labels, y)\n\n    train_loss /= len(train_dataloader)\n    val_loss /= len(test_dataloader)\n    auroc /= len(test_dataloader)\n    acc = confmat_to_accuracy(master_confmat)\n    prec = confmat_to_precision(master_confmat)\n    rec = confmat_to_recall(master_confmat)\n    f1 = confmat_to_f1score(master_confmat)\n\n    print(f'Epoch: {epoch + prev_size}/{EPOCHS + prev_size - 1}')\n    print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n    print(f'Accuracy: {acc * 100:.2f}% | Precision: {prec * 100:.2f}% | Recall: {rec * 100:.2f}% | F1 Score: {f1 * 100:.2f}%')\n    print(f'AUROC: {auroc:.4f}')\n\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    accs.append(acc)\n    precs.append(prec)\n    recs.append(rec)\n    f1s.append(f1)\n    aurocs.append(auroc)\n\n    if acc > best_acc:\n        model_name = f'{unique_file_namer(model.__class__.__name__)}.pth'\n        model_path = os.path.join(model_save_path, model_name)\n        torch.save(model.state_dict(), model_path)\n        print('>>> Model saved!')\n        print(model_path)\n\n        best_acc = acc\n        best_acc_epoch = epoch + prev_size\n    \n    # reloading the best model yet every 5 epochs\n    if epoch % 5 == 4:\n        best_model_name = sorted(os.listdir(model_save_path))[-1]\n        best_model_path = os.path.join(model_save_path, best_model_name)\n        print('Reloaded:', best_model_path)\n\n        model.load_state_dict(torch.load(best_model_path))\n\n    print('\\n' + '=' * 80 + '\\n')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:22:25.746799Z","iopub.execute_input":"2024-05-23T15:22:25.747186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 10))\nplt.title(f'{model.__class__.__name__} Training/Validation Plot')\nplt.axis('off')\n\n# ========== (1) ==========\n\nplt.subplot(2, 1, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nif len(train_losses) <= 20:\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\nplt.grid(True)\nplt.axhline(0, color='black')\nplt.axvline(0, color='black')\nplt.axvline(best_acc_epoch, color='yellow')\nplt.legend(loc='best')\n# plt.ylim(-0.05, 1)\n\n# ========== (2) ==========\n\nplt.subplot(2, 1, 2)\nplt.plot(accs, label='Accuracy')\nplt.plot(precs, label='Precision')\nplt.plot(recs, label='Recall')\nplt.plot(f1s, label='F1 Score')\nplt.plot(aurocs, label='AUROC')\nplt.xlabel('Epoch')\nplt.ylabel('Metrics')\nif len(train_losses) <= 20:\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\nplt.grid(True)\nplt.axhline(1, color='black')\nplt.axvline(0, color='black')\nplt.axvline(best_acc_epoch, color='yellow')\nplt.legend(loc='best')\n\nplot_file_name = f'{unique_file_namer(model.__class__.__name__)}.png'\nplt.savefig(os.path.join(plot_save_path, plot_file_name), bbox_inches='tight')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model_name = sorted(os.listdir(model_save_path))[-1]\nbest_model_path = os.path.join(model_save_path, best_model_name)\nprint(best_model_path)\n\nmodel.load_state_dict(torch.load(best_model_path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = 0\nauroc = 0\nmaster_confmat = torch.zeros(2, 2).to(device)\n\nmodel.eval()\nwith torch.inference_mode():\n    for X, y in tqdm(test_dataloader):\n        X, y = X.to(device), y.to(device)\n        logits = model(X)\n        probs = logits.softmax(1)\n        labels = probs.argmax(1)\n\n        loss += criterion(logits, y).item()\n        auroc += auroc_metric(probs, y).item()\n        master_confmat += confmat_metric(labels, y)\n\nloss /= len(test_dataloader)\nauroc /= len(test_dataloader)\nacc = confmat_to_accuracy(master_confmat)\nprec = confmat_to_precision(master_confmat)\nrec = confmat_to_recall(master_confmat)\nf1 = confmat_to_f1score(master_confmat)\n\nresult = f'Cross Entropy Loss: {loss:.4f} \\nAccuracy: {acc * 100:.2f}% | Precision: {prec * 100:.2f}% | Recall: {rec * 100:.2f}% | F1 Score: {f1 * 100:.2f}% \\nAUROC: {auroc:.4f}'\nprint(result)\n\nresult_file_name = f'{unique_file_namer(model.__class__.__name__)}.txt'\nwith open(os.path.join(result_save_path, result_file_name), 'w') as f:\n    f.write(result)\n\nfig, ax = plot_confusion_matrix(\n    conf_mat=master_confmat.cpu().numpy(),\n    class_names=test_dataset.classes,\n    colorbar=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_pred(test_dataset, model, classes=test_dataset.classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}