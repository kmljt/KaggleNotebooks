{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8389938,"sourceType":"datasetVersion","datasetId":4990354}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kmljts/multiclass-pneumonia-detection?scriptVersionId=178191794\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# import os\n# for root, folders, filenames in os.walk('/kaggle/input'):\n#     print(root, folders)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:01.538276Z","iopub.execute_input":"2024-05-17T11:14:01.539021Z","iopub.status.idle":"2024-05-17T11:14:01.544903Z","shell.execute_reply.started":"2024-05-17T11:14:01.538974Z","shell.execute_reply":"2024-05-17T11:14:01.54391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom torchvision import datasets, transforms, models\nfrom torchmetrics import ConfusionMatrix, AUROC\nfrom mlxtend.plotting import plot_confusion_matrix\n\nimport os\nfrom datetime import datetime, timedelta\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nimport pandas as pd\nimport random\n\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:01.546939Z","iopub.execute_input":"2024-05-17T11:14:01.547808Z","iopub.status.idle":"2024-05-17T11:14:09.257377Z","shell.execute_reply.started":"2024-05-17T11:14:01.547776Z","shell.execute_reply":"2024-05-17T11:14:09.256349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dir = '/kaggle/input'\ndataset_path = os.path.join(input_dir, 'pneumonia-multiclass/chest_xray')\n\noutput_dir = '/kaggle/working'\nmodel_save_path = os.path.join(output_dir, 'models')\nresult_save_path = os.path.join(output_dir, 'results')\nplot_save_path = os.path.join(output_dir, 'plots')\n\nos.makedirs(model_save_path, exist_ok=True)\nos.makedirs(result_save_path, exist_ok=True)\nos.makedirs(plot_save_path, exist_ok=True)\n\ndataset_path, model_save_path, result_save_path, plot_save_path","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:09.258667Z","iopub.execute_input":"2024-05-17T11:14:09.259225Z","iopub.status.idle":"2024-05-17T11:14:09.269921Z","shell.execute_reply.started":"2024-05-17T11:14:09.259191Z","shell.execute_reply":"2024-05-17T11:14:09.2688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:09.27153Z","iopub.execute_input":"2024-05-17T11:14:09.271912Z","iopub.status.idle":"2024-05-17T11:14:09.279058Z","shell.execute_reply.started":"2024-05-17T11:14:09.271879Z","shell.execute_reply":"2024-05-17T11:14:09.278201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sorted(os.listdir(model_save_path)), sorted(os.listdir(result_save_path)), sorted(os.listdir(plot_save_path))","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:09.282352Z","iopub.execute_input":"2024-05-17T11:14:09.28279Z","iopub.status.idle":"2024-05-17T11:14:09.288743Z","shell.execute_reply.started":"2024-05-17T11:14:09.282765Z","shell.execute_reply":"2024-05-17T11:14:09.287892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:09.290191Z","iopub.execute_input":"2024-05-17T11:14:09.290558Z","iopub.status.idle":"2024-05-17T11:14:09.325591Z","shell.execute_reply.started":"2024-05-17T11:14:09.290529Z","shell.execute_reply":"2024-05-17T11:14:09.324752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\nLR = 1e-4\nEPOCHS = 50\n\nANALYZE_DATASET = False\nUSE_BEST_MODEL_YET = False\nNORMALIZE = True","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:09.326782Z","iopub.execute_input":"2024-05-17T11:14:09.327051Z","iopub.status.idle":"2024-05-17T11:14:09.34619Z","shell.execute_reply.started":"2024-05-17T11:14:09.327029Z","shell.execute_reply":"2024-05-17T11:14:09.345213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:09.34755Z","iopub.execute_input":"2024-05-17T11:14:09.348689Z","iopub.status.idle":"2024-05-17T11:14:09.35482Z","shell.execute_reply.started":"2024-05-17T11:14:09.348624Z","shell.execute_reply":"2024-05-17T11:14:09.353829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def current_datetime():\n    cur_datetime = datetime.now() + timedelta(hours=5, minutes=30) # IST\n    return cur_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n\ndef unique_file_namer(model_name, n_epochs=EPOCHS, learning_rate=LR, batch_size=BATCH_SIZE):\n    return f'{current_datetime()}_{model_name}_{n_epochs}_{learning_rate:.2e}_{batch_size}'","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:09.356405Z","iopub.execute_input":"2024-05-17T11:14:09.356966Z","iopub.status.idle":"2024-05-17T11:14:09.370506Z","shell.execute_reply.started":"2024-05-17T11:14:09.356936Z","shell.execute_reply":"2024-05-17T11:14:09.369411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UnNormalize:\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, tensor):\n        return tensor.clamp(-1, 1) * self.std + self.mean\n    \nclass Identity:\n    def __call__(self, tensor):\n        return tensor\n\nimg_to_tensor = transforms.Compose([\n    transforms.Resize((448,) * 2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5]) if NORMALIZE else Identity()\n])\n\ntensor_to_img = transforms.Compose([\n    UnNormalize(0.5, 0.5) if NORMALIZE else Identity(),\n    transforms.ToPILImage(),\n    transforms.Resize((448,) * 2)\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:15:20.559689Z","iopub.execute_input":"2024-05-17T11:15:20.560046Z","iopub.status.idle":"2024-05-17T11:15:20.567993Z","shell.execute_reply.started":"2024-05-17T11:15:20.560018Z","shell.execute_reply":"2024-05-17T11:15:20.56701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_sample(dataset, classes):\n    input, target = random.choice(dataset)\n\n    image = tensor_to_img(input)\n    display(image)\n    print('Target:', classes[target])\n\ndef random_pred(dataset, model, classes):\n    input, target = random.choice(dataset)\n\n    input = input.to(device)\n    image = tensor_to_img(input)\n    display(image)\n\n    model.eval()\n    with torch.inference_mode():\n        logits = model(input.unsqueeze(0)).squeeze()\n\n    print(f'{\"Raw Logits: \":30}{logits}') # raw logits\n    probs = logits.softmax(0)\n    print(f'{\"Prediction Probabilities: \":30}{probs}') # prediction probabilities\n    label = probs.argmax(0).item()\n    print(f'{\"Prediction Labels: \":30}{label}', end='\\n\\n') # prediction label\n    \n    print('Prediction:', classes[label])\n    print('Target:', classes[target])\n\ndef dataset_analyzer(dataset, classes):\n    freqs = [0] * len(classes)\n    for X, y in dataset:\n        freqs[y] += 1\n\n    return {classes[i]: freqs[i] for i in range(len(classes))}","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:09.388025Z","iopub.execute_input":"2024-05-17T11:14:09.388671Z","iopub.status.idle":"2024-05-17T11:14:09.401418Z","shell.execute_reply.started":"2024-05-17T11:14:09.388645Z","shell.execute_reply":"2024-05-17T11:14:09.40035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def harmonic_mean(a, b):\n    if a + b == 0: return 0\n    return 2 * a * b / (a + b)\n\ndef manage_nan(tensor):\n    return tensor if not torch.isnan(tensor).item() else torch.tensor(0.0).to(device)\n\ndef confmat_to_accuracy(confmat): # micro\n    num_classes = confmat.shape[0]\n\n    correct_preds = 0\n    for i in range(num_classes):\n        correct_preds += confmat[i, i]\n    all_preds = confmat.sum()\n\n    acc = manage_nan(correct_preds / all_preds)\n\n    return acc.item()\n\ndef confmat_to_precision(confmat): # macro\n    num_classes = confmat.shape[0]\n\n    if num_classes == 2:\n        return manage_nan(confmat[1, 1] / confmat[:, 1].sum()).item()\n\n    prec = 0\n    for i in range(num_classes):\n        prec += manage_nan(confmat[i, i] / confmat[:, i].sum())\n    prec /= num_classes\n\n    return prec.item()\n\ndef confmat_to_recall(confmat): # macro\n    num_classes = confmat.shape[0]\n\n    if num_classes == 2:\n        return manage_nan(confmat[1, 1] / confmat[1].sum()).item()\n\n    rec = 0\n    for i in range(num_classes):\n        rec += manage_nan(confmat[i, i] / confmat[i].sum())\n    rec /= num_classes\n\n    return rec.item()\n\ndef confmat_to_f1score(confmat): # macro\n    num_classes = confmat.shape[0]\n\n    if num_classes == 2:\n        return harmonic_mean(confmat_to_precision(confmat), confmat_to_recall(confmat))\n\n    f1 = 0\n    for i in range(num_classes):\n        prec = manage_nan(confmat[i, i] / confmat[:, i].sum())\n        rec = manage_nan(confmat[i, i] / confmat[i].sum())\n\n        f1 += harmonic_mean(prec, rec)\n    f1 /= num_classes\n\n    return f1.item()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:09.402532Z","iopub.execute_input":"2024-05-17T11:14:09.402793Z","iopub.status.idle":"2024-05-17T11:14:09.417663Z","shell.execute_reply.started":"2024-05-17T11:14:09.402771Z","shell.execute_reply":"2024-05-17T11:14:09.416719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = datasets.ImageFolder(dataset_path, transform=img_to_tensor)\n\nlen(dataset), random.choice(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:09.418908Z","iopub.execute_input":"2024-05-17T11:14:09.419514Z","iopub.status.idle":"2024-05-17T11:14:12.30707Z","shell.execute_reply.started":"2024-05-17T11:14:09.419488Z","shell.execute_reply":"2024-05-17T11:14:12.306207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.classes, dataset.class_to_idx","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:12.310704Z","iopub.execute_input":"2024-05-17T11:14:12.310963Z","iopub.status.idle":"2024-05-17T11:14:12.316866Z","shell.execute_reply.started":"2024-05-17T11:14:12.310941Z","shell.execute_reply":"2024-05-17T11:14:12.315995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_sample(dataset, classes=dataset.classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:12.31789Z","iopub.execute_input":"2024-05-17T11:14:12.318142Z","iopub.status.idle":"2024-05-17T11:14:12.392478Z","shell.execute_reply.started":"2024-05-17T11:14:12.318119Z","shell.execute_reply":"2024-05-17T11:14:12.391625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length = len(dataset)\nsplit_ratio = (0.7, 0.1, 0.2)\ntrain_size = int(length * split_ratio[0])\nval_size = int(length * split_ratio[1])\ntest_size = length - train_size - val_size\n\ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n\nlen(train_dataset), len(val_dataset), len(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:12.393512Z","iopub.execute_input":"2024-05-17T11:14:12.393765Z","iopub.status.idle":"2024-05-17T11:14:12.401873Z","shell.execute_reply.started":"2024-05-17T11:14:12.393743Z","shell.execute_reply":"2024-05-17T11:14:12.401037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if ANALYZE_DATASET:\n    train_dataset_info = dataset_analyzer(train_dataset, classes=dataset.classes)\n    val_dataset_info = dataset_analyzer(val_dataset, classes=dataset.classes)\n    test_dataset_info = dataset_analyzer(test_dataset, classes=dataset.classes)\n\n    df = pd.DataFrame([train_dataset_info, val_dataset_info, test_dataset_info], index=['Train', 'Validation', 'Test'])\n    df_splitwise_perc = df.copy()\n    df.loc['Total'] = df.sum()\n    df_classwise_perc = df.copy()\n    display(df)\n\n    df_classwise_perc.loc['Train Class-wise %'] = df_classwise_perc.loc['Train'] / df_classwise_perc.loc['Train'].sum()\n    df_classwise_perc.loc['Validation Class-wise %'] = df_classwise_perc.loc['Validation'] / df_classwise_perc.loc['Validation'].sum()\n    df_classwise_perc.loc['Test Class-wise %'] = df_classwise_perc.loc['Test'] / df_classwise_perc.loc['Test'].sum()\n    df_classwise_perc.loc['Total Class-wise %'] = df_classwise_perc.loc['Total'] / df_classwise_perc.loc['Total'].sum()\n    df_classwise_perc = df_classwise_perc.drop(['Train', 'Validation', 'Test', 'Total'])\n    display(df_classwise_perc)\n\n    df_splitwise_perc['NORMAL Split-wise %'] = df_splitwise_perc['NORMAL'] / df_splitwise_perc['NORMAL'].sum()\n    df_splitwise_perc['PNEUMONIA_BACTERIAL Split-wise %'] = df_splitwise_perc['PNEUMONIA_BACTERIAL'] / df_splitwise_perc['PNEUMONIA_BACTERIAL'].sum()\n    df_splitwise_perc['PNEUMONIA_VIRAL Split-wise %'] = df_splitwise_perc['PNEUMONIA_VIRAL'] / df_splitwise_perc['PNEUMONIA_VIRAL'].sum()\n    df_splitwise_perc = df_splitwise_perc.drop(['NORMAL', 'PNEUMONIA_BACTERIAL', 'PNEUMONIA_VIRAL'], axis=1)\n    display(df_splitwise_perc)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:12.403123Z","iopub.execute_input":"2024-05-17T11:14:12.403398Z","iopub.status.idle":"2024-05-17T11:14:12.416582Z","shell.execute_reply.started":"2024-05-17T11:14:12.403375Z","shell.execute_reply":"2024-05-17T11:14:12.415782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n\nlen(train_dataloader), len(val_dataloader), len(test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:12.417692Z","iopub.execute_input":"2024-05-17T11:14:12.418314Z","iopub.status.idle":"2024-05-17T11:14:12.42853Z","shell.execute_reply.started":"2024-05-17T11:14:12.418282Z","shell.execute_reply":"2024-05-17T11:14:12.427377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_samples = torch.tensor([1583, 2780, 1493]).to(device)\n\nn_samples","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:12.429517Z","iopub.execute_input":"2024-05-17T11:14:12.429798Z","iopub.status.idle":"2024-05-17T11:14:12.593261Z","shell.execute_reply.started":"2024-05-17T11:14:12.429775Z","shell.execute_reply":"2024-05-17T11:14:12.592203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weights = n_samples.sum() / n_samples\n\nclass_weights","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:12.59472Z","iopub.execute_input":"2024-05-17T11:14:12.595321Z","iopub.status.idle":"2024-05-17T11:14:12.897413Z","shell.execute_reply.started":"2024-05-17T11:14:12.595287Z","shell.execute_reply":"2024-05-17T11:14:12.896304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PneumoniaDetector(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.resnet = models.resnet18(weights='DEFAULT')\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 3) # in_features = 512\n\n    def forward(self, x):\n        return self.resnet(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:12.898592Z","iopub.execute_input":"2024-05-17T11:14:12.898963Z","iopub.status.idle":"2024-05-17T11:14:12.904686Z","shell.execute_reply.started":"2024-05-17T11:14:12.898933Z","shell.execute_reply":"2024-05-17T11:14:12.903691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = PneumoniaDetector().to(device)\n\nif USE_BEST_MODEL_YET:\n    best_model_name = sorted(os.listdir(model_save_path))[-1]\n    best_model_path = os.path.join(model_save_path, best_model_name)\n    print(best_model_path)\n    model.load_state_dict(torch.load(best_model_path))","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:12.905917Z","iopub.execute_input":"2024-05-17T11:14:12.906261Z","iopub.status.idle":"2024-05-17T11:14:13.606238Z","shell.execute_reply.started":"2024-05-17T11:14:12.906229Z","shell.execute_reply":"2024-05-17T11:14:13.605131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nwith torch.inference_mode():\n    pred = model(random.choice(train_dataset)[0].to(device).unsqueeze(0))\npred","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:13.607802Z","iopub.execute_input":"2024-05-17T11:14:13.608219Z","iopub.status.idle":"2024-05-17T11:14:14.253356Z","shell.execute_reply.started":"2024-05-17T11:14:13.608164Z","shell.execute_reply":"2024-05-17T11:14:14.252348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_pred(train_dataset, model, classes=dataset.classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:14.254634Z","iopub.execute_input":"2024-05-17T11:14:14.254961Z","iopub.status.idle":"2024-05-17T11:14:14.369149Z","shell.execute_reply.started":"2024-05-17T11:14:14.254931Z","shell.execute_reply":"2024-05-17T11:14:14.368221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# criterion = nn.CrossEntropyLoss(weight=class_weights)\ncriterion = nn.CrossEntropyLoss()\nconfmat_metric = ConfusionMatrix(task='multiclass', num_classes=3).to(device)\nauroc_metric = AUROC(task='multiclass', num_classes=3).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=LR)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:14.370323Z","iopub.execute_input":"2024-05-17T11:14:14.370607Z","iopub.status.idle":"2024-05-17T11:14:14.37896Z","shell.execute_reply.started":"2024-05-17T11:14:14.370582Z","shell.execute_reply":"2024-05-17T11:14:14.377954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses = []\nval_losses = []\naccs = []\nprecs = []\nrecs = []\nf1s = []\naurocs = []","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:14.380258Z","iopub.execute_input":"2024-05-17T11:14:14.384079Z","iopub.status.idle":"2024-05-17T11:14:14.388451Z","shell.execute_reply.started":"2024-05-17T11:14:14.384045Z","shell.execute_reply":"2024-05-17T11:14:14.387695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses, val_losses, accs, precs, recs, f1s, aurocs","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:14.389484Z","iopub.execute_input":"2024-05-17T11:14:14.389731Z","iopub.status.idle":"2024-05-17T11:14:14.399932Z","shell.execute_reply.started":"2024-05-17T11:14:14.389709Z","shell.execute_reply":"2024-05-17T11:14:14.399112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = 0\nauroc = 0\nmaster_confmat = torch.zeros(3, 3).to(device)\n\nmodel.eval()\nwith torch.inference_mode():\n    for X, y in tqdm(val_dataloader):\n        X, y = X.to(device), y.to(device)\n        logits = model(X)\n        probs = logits.softmax(1)\n        labels = probs.argmax(1)\n\n        loss += criterion(logits, y).item()\n        auroc += auroc_metric(probs, y).item()\n        master_confmat += confmat_metric(labels, y)\n\nloss /= len(val_dataloader)\nauroc /= len(val_dataloader)\nacc = confmat_to_accuracy(master_confmat)\nprec = confmat_to_precision(master_confmat)\nrec = confmat_to_recall(master_confmat)\nf1 = confmat_to_f1score(master_confmat)\n\ntrain_losses.append(loss)\nval_losses.append(loss)\naccs.append(acc)\nprecs.append(prec)\nrecs.append(rec)\nf1s.append(f1)\naurocs.append(auroc)\n\nprint(f'Cross Entropy Loss: {loss:.4f}')\nprint(f'Accuracy: {acc * 100:.2f}% | Precision: {prec * 100:.2f}% | Recall: {rec * 100:.2f}% | F1 Score: {f1 * 100:.2f}%')\nprint(f'AUROC: {auroc:.4f}')\n\nfig, ax = plot_confusion_matrix(\n    conf_mat=master_confmat.cpu().numpy(),\n    class_names=dataset.classes,\n    colorbar=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:12:16.842834Z","iopub.execute_input":"2024-05-17T11:12:16.84311Z","iopub.status.idle":"2024-05-17T11:12:35.522493Z","shell.execute_reply.started":"2024-05-17T11:12:16.843087Z","shell.execute_reply":"2024-05-17T11:12:35.521564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_acc = acc\nbest_acc_epoch = 0","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:12:35.527162Z","iopub.execute_input":"2024-05-17T11:12:35.527543Z","iopub.status.idle":"2024-05-17T11:12:35.531592Z","shell.execute_reply.started":"2024-05-17T11:12:35.527518Z","shell.execute_reply":"2024-05-17T11:12:35.530569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prev_size = len(train_losses)\n\nfor epoch in tqdm(range(EPOCHS)):\n    train_loss = 0\n    val_loss = 0\n    auroc = 0\n    master_confmat = torch.zeros(3, 3).to(device)\n\n    model.train()\n    for X, y in tqdm(train_dataloader):\n        X, y = X.to(device), y.to(device)\n        pred = model(X)\n        loss = criterion(pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    model.eval()\n    with torch.inference_mode():\n        for X, y in tqdm(val_dataloader):\n            X, y = X.to(device), y.to(device)\n            logits = model(X)\n            probs = logits.softmax(1)\n            labels = probs.argmax(1)\n\n            val_loss += criterion(logits, y).item()\n            auroc += auroc_metric(probs, y).item()\n            master_confmat += confmat_metric(labels, y)\n\n    train_loss /= len(train_dataloader)\n    val_loss /= len(val_dataloader)\n    auroc /= len(val_dataloader)\n    acc = confmat_to_accuracy(master_confmat)\n    prec = confmat_to_precision(master_confmat)\n    rec = confmat_to_recall(master_confmat)\n    f1 = confmat_to_f1score(master_confmat)\n\n    print(f'Epoch: {epoch + prev_size}/{EPOCHS + prev_size - 1}')\n    print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n    print(f'Accuracy: {acc * 100:.2f}% | Precision: {prec * 100:.2f}% | Recall: {rec * 100:.2f}% | F1 Score: {f1 * 100:.2f}%')\n    print(f'AUROC: {auroc:.4f}')\n\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    accs.append(acc)\n    precs.append(prec)\n    recs.append(rec)\n    f1s.append(f1)\n    aurocs.append(auroc)\n\n    if acc > best_acc:\n        model_name = f'{unique_file_namer(model.__class__.__name__)}.pth'\n        model_path = os.path.join(model_save_path, model_name)\n        torch.save(model.state_dict(), model_path)\n        print('>>> Model saved!')\n        print(model_path)\n\n        best_acc = acc\n        best_acc_epoch = epoch + prev_size\n    \n    # reloading the best model yet every 5 epochs\n    if epoch % 5 == 4:\n        best_model_name = sorted(os.listdir(model_save_path))[-1]\n        best_model_path = os.path.join(model_save_path, best_model_name)\n        print('Reloaded:', best_model_path)\n\n        model.load_state_dict(torch.load(best_model_path))\n\n    print('\\n' + '=' * 80 + '\\n')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:12:35.532986Z","iopub.execute_input":"2024-05-17T11:12:35.533365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 10))\nplt.title(f'{model.__class__.__name__} Training/Validation Plot')\nplt.axis('off')\n\n# ========== (1) ==========\n\nplt.subplot(2, 1, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nif len(train_losses) <= 20:\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\nplt.grid(True)\nplt.axhline(0, color='black')\nplt.axvline(0, color='black')\nplt.axvline(best_acc_epoch, color='cyan')\nplt.legend(loc='best')\n# plt.ylim(-0.05, 1)\n\n# ========== (2) ==========\n\nplt.subplot(2, 1, 2)\nplt.plot(accs, label='Accuracy')\nplt.plot(precs, label='Precision')\nplt.plot(recs, label='Recall')\nplt.plot(f1s, label='F1 Score')\nplt.plot(aurocs, label='AUROC')\nplt.xlabel('Epoch')\nplt.ylabel('Metrics')\nif len(train_losses) <= 20:\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\nplt.grid(True)\nplt.axhline(1, color='black')\nplt.axvline(0, color='black')\nplt.axvline(best_acc_epoch, color='cyan')\nplt.legend(loc='best')\n\nplot_file_name = f'{unique_file_namer(model.__class__.__name__)}.png'\nplt.savefig(os.path.join(plot_save_path, plot_file_name), bbox_inches='tight')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model_name = sorted(os.listdir(model_save_path))[-1]\nbest_model_path = os.path.join(model_save_path, best_model_name)\nprint(best_model_path)\n\nmodel.load_state_dict(torch.load(best_model_path))","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:14:36.810805Z","iopub.execute_input":"2024-05-17T11:14:36.811224Z","iopub.status.idle":"2024-05-17T11:14:36.878086Z","shell.execute_reply.started":"2024-05-17T11:14:36.811187Z","shell.execute_reply":"2024-05-17T11:14:36.877211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = 0\nauroc = 0\nmaster_confmat = torch.zeros(3, 3).to(device)\n\nmodel.eval()\nwith torch.inference_mode():\n    for X, y in tqdm(test_dataloader):\n        X, y = X.to(device), y.to(device)\n        logits = model(X)\n        probs = logits.softmax(1)\n        labels = probs.argmax(1)\n\n        loss += criterion(logits, y).item()\n        auroc += auroc_metric(probs, y).item()\n        master_confmat += confmat_metric(labels, y)\n\nloss /= len(test_dataloader)\nauroc /= len(test_dataloader)\nacc = confmat_to_accuracy(master_confmat)\nprec = confmat_to_precision(master_confmat)\nrec = confmat_to_recall(master_confmat)\nf1 = confmat_to_f1score(master_confmat)\n\nresult = f'Cross Entropy Loss: {loss:.4f} \\nAccuracy: {acc * 100:.2f}% | Precision: {prec * 100:.2f}% | Recall: {rec * 100:.2f}% | F1 Score: {f1 * 100:.2f}% \\nAUROC: {auroc:.4f}'\nprint(result)\n\nresult_file_name = f'{unique_file_namer(model.__class__.__name__)}.txt'\nwith open(os.path.join(result_save_path, result_file_name), 'w') as f:\n    f.write(result)\n\nfig, ax = plot_confusion_matrix(\n    conf_mat=master_confmat.cpu().numpy(),\n    class_names=dataset.classes,\n    colorbar=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_pred(test_dataset, model, classes=dataset.classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:20:34.55713Z","iopub.execute_input":"2024-05-17T11:20:34.558108Z","iopub.status.idle":"2024-05-17T11:20:34.6482Z","shell.execute_reply.started":"2024-05-17T11:20:34.558073Z","shell.execute_reply":"2024-05-17T11:20:34.647291Z"},"trusted":true},"execution_count":null,"outputs":[]}]}